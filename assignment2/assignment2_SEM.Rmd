---
title: 'Assignment 2: Task 2 - SEM'
author: "Group 11"
date: '30.10.2018'
output: pdf_document 
---
\section{0. Load Libraries}

```{r, message=FALSE, warning=FALSE}
library(lavaan)
library(plotrix)
library(lessR)
library(semPlot)


```


\section{1. Problem Statement}
We are given a dataset containing the covariance  matrix  on  some  basic statistical measures and two advanced measurements of 320 basketball players during the NBA 2017-2018 season. There are also two advanced measurements (Y1, Y2) about offensive performance of the players. Additionally, we are given a hypothesized model of the causal relationships between the observed constructs, which should be tested for the statistics of the fit.


\section{2. Descriptive Statistics}
In the raw data, we are given the covariance matrix of 320 observations measured by 8 variables. For interpretability we converted the covariance matrix into a correlation matrix and visualized it in a heatmap. The correlations are either very high (>0.9) or very low (<0.2) with some mid ranged values in between a range of [0.29, 0.45]. Within the basic statistical measurements only X1 and X3 are highly correlated. Both X1 and X3 are strongly correlated with one of the advanced measures, Y1.


```{r}
cov <-read.delim("../data/advanced_basketball.txt", header = TRUE, sep="",dec = ".", skipNul = FALSE)
cov <- cov[-1]
cov <- cov[-c(1,2,3),]
rownames(cov) = c("X1","X2","X3","Y1","Y2")
colnames(cov) = c("X1","X2","X3","Y1","Y2")
cov <- as.matrix(cov)
cov

color2D.matplot(cov2cor(cov),show.values=4,axes=FALSE,
  xlab="",ylab="")

axis(1,at=0.5:4.5,labels=rownames(cov))
axis(2,at=4.5:0.5,labels=colnames(cov))

```


\section{3. Assumptions}
First, we assume multivariate normal distribution. When the maximum likelihood method is used the data is required to be multivariate normally distributed, as small changes in multivariate normality can lead to a large difference in the chi-square test.
Additionally, equations must be greater than the estimated parameters or models should be over identified or exact identified. Under-identified models are not considered. Specifically, we have 15 inputs and 11 parameters to be estimated, which satisfies the condition of $p\leq inputs$. 


\section{4. Method}
The objective of structural equation models is to explain the covariances of the observed variables in terms of the relationships of these variables to the assumed underlying latent variables and the relationships pos-
tulated between the latent variables themselves. SEM involves estimating a number of model parameters from the observed covariance matrix $S^{obs}$ to minimize the difference between this matrix and a matrix $S^i$ implied by the fitted model. The most commonly used method of estimation for SEM is maximum likelihood under the assumption that the observed data have a multivariate normal distribution. Y1 and Y2 represent endogenous variables, which means that their variance is considered to be explained in part by other variables in the model.
X1, X2 and X3 are exgoneous variables whose variance is assumed to be caused by variables not in the causal model.

First, we construct the hypothesized model in lavaan syntax and execute the sem function with a Maximum Likelihood estimation. There are other estimation procedures, but ML is the most efficient when the dataset is large, the data are multivariate normal distributed and the input is a covariance matrix. All these assumptions are satisfied for our task.

```{r}
model <- '
# regressions
Y1 ~ X1 + X2 + Y2
Y2 ~ X1 + X3
# residual covariance
X1 ~~ X3 
'

GFI <- function(Si, Sobs){
  if( class(Si) == "list"){
    Si <- as.matrix(as.data.frame(Si$cov))
  }
  
  nominator <- sum(diag(solve(Si) %*% Sobs - diag(ncol(Sobs))))^2
  denominator <- sum(diag(solve(Si) %*% Sobs))^2
  return(1 - (nominator / denominator))
}


fit <- lavaan::sem(model,sample.nobs = 320,sample.cov=cov, fixed.x=F)
# see appendix
#summary(fit, fit.measures=TRUE)
Si2 <- as.matrix(as.data.frame(fitted(fit)$cov))
Si2 <- corReorder(R = Si2, vars = c(X1, X2, X3, Y1, Y2), heat.map = F)
GFI(Si = Si2, Sobs = cov)

```

```{r fig.height=3, fig.width=3}
semPaths(fit, "std",edge.label.cex = 2.0, cex=1.5, curvePivot = TRUE)

```


\section{5. Interpretation}

The Goodness-of-fit (GFI) value of 0.99 (>0.95) and Comparative Fit Index (CFI) 0.977 (>0.95)  imply that the data is a good fit. Moreover, AIC (Akaike's Information Criterion) estimates the quality of each model, and it is better to obtain a smaller AIC. In our model it is at 3515.273, but this information is only useful when comparing it with a modified version of the model. The Standardized Root Mean Square Residual (SRMR) is defined as the standardized difference between the observed correlation and the predicted correlation and anything below 0.8 is considered a good fit, while we have a value of 0.152 in this model. 
The overall p- value (0.000) of the Chi-Square test suggests to reject H0, indicating that we cannot assume $S^i$ and $S^{obs}$ to be equal. This test is very sensitive to sample size and given the large sample of 320 observations might be cause for this. We attach more weight to the GFI index, which represents the proportion of the variances and covariances explained by the model. CFI measures whether the model fits the data better than a more restricted baseline model and we therefore conclude, that the model fits the data. The full summary of all the values can be seen in the appendix.

Nevertheless, we attempted to improve the model by adjusting the hypothesized structure. We noticed, that the residual covariances of the model are not too small indicating that there are some related causes which have not been identified yet. This holds especially for X2 and Y2 and X3 and X2, and X1 and X2.


```{r}
modindices(fit, sort=T)
resid(fit)$cov
```

Modification indices state how model fit would change if you added new parameters to the model. We sorted the modification indices by mi which is an estimate of how much the model fit would improve if each parameter were added. 
The first suggestion is a regression of Y1, "an average estimate of how many offensive plays the player was involved in, per game", on X2, "average number of assists per game". However, this would not make any sense, since X2 is a basic measurement that an advanced measure should not regress on. The suggested modifications do not take the logic behind the model into account, as SEM is not an exploratory technique, but rather used to validate a theoretically solid model. It is important to consider the overall objective of CFA is to confirm, not to explore, which is why following all modification indices can be dangerous, as it can lead to over-fitting the data and decreasing the generalizability of the results.

We adjusted the second modification suggestion and added a residual covariance between X1, "average points per
game" and X2, "average number of assists per game". 
This resulted in an improved CFI (0.983) and an improved AIC (3502.237) and SRMR (0.131), but almost no change in all the other evaluation measures. The p-value still indicates a rejection of H0. 
We then also added a covariance between X1 and X2 to the model which further improved the CFI (0.994) and AIC (3475.934) also decreased. The SRMR greatly decreased to a value of 0.021, surpassing the lower threshold of 0.8 which is considered to be an indicator of a good fit.
The remaining modification indices and residuals imply that further improvement could be yielded by adding the regression of X2 on Y2. Theoretically, this would again not make sense, because shooting efficiency (Y2) is not dependant on assists (X2). The structure is visualized below.


```{r}
model2 <- '
# regressions
Y1 ~ X1 + X2 + Y2
Y2 ~ X1 + X3
# residual covariance
X1 ~~ X3
X2 ~~ X3
X1 ~~ X2
'

fit2 <- lavaan::sem(model2,sample.nobs = 320,sample.cov=cov)
```

```{r fig.height=3, fig.width=3}
semPaths(fit2, "std",edge.label.cex = 2.0, cex=1.5, curvePivot = TRUE)
#summary(fit2, fit.measures=T)
```

It is also possible, to identify relationships, which are not needed. "Shot attempts" (X3) has an indirect effect on "offensive plays" (Y1) through "shooting efficiency" (Y2). As Y1 is already regressed on by one of the variables determining shooting efficiency (X1), and deleting the regression of Y2 on Y1 did not indicate a large drop in Chi-Square from the modification indices, we tested a model with a direct link between X3 and Y1 and no regression of Y2 on Y1. This model had slightly improved statistical measures (AIC= 3472.458, p-value= 0.001, GIF and SMRS stayed equal) in comparison to the previous 'model2'.  

```{r}
model3 <- '
# regressions
Y1 ~ X1 + X2 + X3
Y2 ~ X1 + X3 
# residual covariance
X1 ~~ X3
X2 ~~ X3
X1 ~~ X2
'

fit3 <- lavaan::sem(model3,sample.nobs = 320,sample.cov=cov)

#summary(fit3, fit.measures=T)
Si2 <- as.matrix(as.data.frame(fitted(fit3)$cov))
Si2 <- corReorder(R = Si2, vars = c(X1, X2, X3, Y1, Y2), heat.map = F)
GFI(Si = Si2, Sobs = cov)

```


```{r fig.height=3, fig.width=3}
semPaths(fit3, "std",edge.label.cex = 2.0, cex=1.5, curvePivot = TRUE)
```

We conducted an anova to compare the modified models which confirmed the significant improvement of 'model3' over 'model2'.

```{r}
anova(fit3,fit2)
```



\section{6. Alternatives}

In our attempt at improving the model, we incrementally added variables, as described before and yielded another model, as seen below, which achieves the statistically best values, with a p-value of 0.019, CFI of 0.998, RMSEA of 0.118, AIC of 3467.0 and GFI of 0.999. However, we do not consider the structure useful, as it makes the model overly complex. It also introduces a regression of "number of assists" (X2) on "shooting efficiency" (Y2) which is not logically consistent. We therefore discarded this modification.

```{r}

model4 <- '
# regressions
Y1 ~ X1 + X2 + Y2 
Y2 ~ X1 + X3 + X2
# residual covariance
X1 ~~ X3
X2 ~~ X3
X1 ~~ X2
'
fit4 <- lavaan::sem(model4,sample.nobs = 320,sample.cov=cov)

```



\section{7. Conclusion}
We evaluated the fit of a path model using different evaluation measures and concluded that the model is a good representation of the data. We attempted to improve the model and assessed multiple structural changes. 
We compared the fit of the improved models with each other, which revealed that 'model3' fits the data even better, while keeping the underlying theoretical concepts intact.  



\section{Appendix}
```{r}
summary(fit, fit.measures=TRUE)
```
\newpage
```{r}

summary(fit2, fit.measures=TRUE)
summary(fit3, fit.measures=TRUE)
summary(fit4, fit.measures=TRUE)
```
